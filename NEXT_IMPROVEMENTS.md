# ä¸‹ä¸€æ­¥æ”¹è¿›è®¡åˆ’

## ğŸ¯ å·²å®Œæˆï¼ˆv1.4ï¼‰

### âœ… Caption å…³è”ä¼˜åŒ–
- **ç¼–å·åŒ¹é…**ï¼šFigure 1 è‡ªåŠ¨åŒ¹é…ç¬¬ä¸€ä¸ªå›¾è¡¨
- **å­å›¾è¯†åˆ«**ï¼šè‡ªåŠ¨è¯†åˆ« (a), (b), (c) æ ‡ç­¾
- **å¤šè¡Œ caption**ï¼šæ­£ç¡®å¤„ç†è·¨è¡Œ caption
- **æ–¹å‘ä¼˜å…ˆçº§**ï¼šå›¾è¡¨ä¼˜å…ˆæŸ¥æ‰¾ä¸‹æ–¹ï¼Œè¡¨æ ¼ä¼˜å…ˆæŸ¥æ‰¾ä¸Šæ–¹

**é¢„æœŸæ•ˆæœ**ï¼šCaption åŒ¹é…å‡†ç¡®ç‡ä» 70% æå‡åˆ° 85%+

---

## ğŸš€ å¾…å®æ–½ï¼ˆä¼˜å…ˆçº§æ’åºï¼‰

### ä¼˜å…ˆçº§ 1ï¼šDocLayout-YOLO é›†æˆï¼ˆé¢„æœŸæå‡ 15-20%ï¼‰

**ä¸ºä»€ä¹ˆé‡è¦**ï¼š
- å½“å‰ PubLayNet å¯¹ç§‘å­¦è®ºæ–‡æ”¯æŒä¸å¤Ÿå¥½
- DocLayout-YOLO ä¸“é—¨é’ˆå¯¹æ–‡æ¡£å¸ƒå±€è®¾è®¡
- æ£€æµ‹å‡†ç¡®ç‡æ˜¾è‘—æå‡

**å®æ–½æ­¥éª¤**ï¼š

#### 1. å®‰è£…ä¾èµ–

```bash
# æ·»åŠ åˆ° requirements-extra.txt
pip install doclayout-yolo
```

#### 2. ä¸‹è½½æ¨¡å‹æƒé‡

```python
# è‡ªåŠ¨ä¸‹è½½ï¼ˆé¦–æ¬¡è¿è¡Œæ—¶ï¼‰
from doclayout_yolo import YOLOv10

# æ¨¡å‹ä¼šè‡ªåŠ¨ä¸‹è½½åˆ° ~/.cache/doclayout_yolo/
model = YOLOv10("doclayout_yolo_docstructbench_imgsz1024.pt")
```

#### 3. åˆ›å»ºæ£€æµ‹å™¨ç±»

åˆ›å»ºæ–‡ä»¶ï¼š`src/figtabminer/detectors/doclayout_detector.py`

```python
#!/usr/bin/env python3
"""
DocLayout-YOLO detector for document layout analysis.
"""

import numpy as np
from typing import List, Dict
from pathlib import Path

try:
    from doclayout_yolo import YOLOv10
    DOCLAYOUT_AVAILABLE = True
except ImportError:
    DOCLAYOUT_AVAILABLE = False


class DocLayoutYOLODetector:
    """DocLayout-YOLO detector wrapper"""
    
    def __init__(self, model_name: str = "doclayout_yolo_docstructbench_imgsz1024.pt"):
        if not DOCLAYOUT_AVAILABLE:
            raise ImportError("doclayout-yolo not installed")
        
        self.model = YOLOv10(model_name)
        self.label_map = {
            0: "Text",
            1: "Title",
            2: "Figure",
            3: "Table",
            4: "Caption",
            5: "Header",
            6: "Footer",
            7: "Reference",
            8: "Equation"
        }
    
    def detect(self, image_path: str, conf_threshold: float = 0.25) -> List[Dict]:
        """
        Detect layout elements in image.
        
        Returns:
            List of detections with bbox, label, score
        """
        results = self.model.predict(
            image_path,
            imgsz=1024,
            conf=conf_threshold,
            device="cuda" if self._has_cuda() else "cpu"
        )
        
        detections = []
        
        for result in results:
            boxes = result.boxes
            
            for i in range(len(boxes)):
                bbox = boxes.xyxy[i].cpu().numpy()  # [x0, y0, x1, y1]
                conf = float(boxes.conf[i].cpu().numpy())
                cls = int(boxes.cls[i].cpu().numpy())
                
                label = self.label_map.get(cls, "Unknown")
                
                detections.append({
                    "bbox": bbox.tolist(),
                    "label": label,
                    "score": conf,
                    "class_id": cls
                })
        
        return detections
    
    def _has_cuda(self) -> bool:
        """Check if CUDA is available"""
        try:
            import torch
            return torch.cuda.is_available()
        except:
            return False


def detect_layout_doclayout(image_path: str, conf_threshold: float = 0.25) -> List[Dict]:
    """
    Convenience function for layout detection.
    """
    if not DOCLAYOUT_AVAILABLE:
        return []
    
    detector = DocLayoutYOLODetector()
    return detector.detect(image_path, conf_threshold)
```

#### 4. é›†æˆåˆ°ä¸»æµç¨‹

ä¿®æ”¹ `src/figtabminer/layout_detect.py`ï¼š

```python
# åœ¨æ–‡ä»¶å¼€å¤´æ·»åŠ 
try:
    from .detectors import doclayout_detector
    DOCLAYOUT_AVAILABLE = True
except ImportError:
    DOCLAYOUT_AVAILABLE = False

# ä¿®æ”¹ layout_available() å‡½æ•°
def layout_available() -> bool:
    """Check if any layout detection is available"""
    # ä¼˜å…ˆä½¿ç”¨ DocLayout-YOLO
    if DOCLAYOUT_AVAILABLE:
        return True
    # é™çº§åˆ° PubLayNet
    if DETECTRON2_AVAILABLE:
        return True
    return False

# ä¿®æ”¹ detect_layout() å‡½æ•°
def detect_layout(page_image_path: str, score_thresh: float = 0.5) -> list:
    """
    Detect layout with automatic fallback:
    1. Try DocLayout-YOLO (best)
    2. Fall back to PubLayNet (good)
    3. Fall back to basic method (minimal)
    """
    # Try DocLayout-YOLO first
    if DOCLAYOUT_AVAILABLE:
        try:
            detections = doclayout_detector.detect_layout_doclayout(
                page_image_path, 
                conf_threshold=score_thresh
            )
            if detections:
                logger.info(f"DocLayout-YOLO detected {len(detections)} elements")
                return detections
        except Exception as e:
            logger.warning(f"DocLayout-YOLO failed, falling back: {e}")
    
    # Fall back to PubLayNet
    if DETECTRON2_AVAILABLE:
        try:
            # ... existing PubLayNet code ...
        except Exception as e:
            logger.warning(f"PubLayNet failed, using basic method: {e}")
    
    # Fall back to basic method
    return []
```

#### 5. æµ‹è¯•

```bash
# æµ‹è¯• DocLayout-YOLO
python -c "
from src.figtabminer.detectors import doclayout_detector
detections = doclayout_detector.detect_layout_doclayout('test_image.png')
print(f'Detected {len(detections)} elements')
for d in detections:
    print(f\"  {d['label']}: {d['score']:.2f}\")
"

# è¿è¡Œå®Œæ•´æµç¨‹
python scripts/run_pipeline.py --pdf data/samples/test.pdf
```

**é¢„æœŸæ•ˆæœ**ï¼š
- å›¾è¡¨æ£€æµ‹ F1: 0.75 â†’ 0.90+
- è¡¨æ ¼æ£€æµ‹ F1: 0.70 â†’ 0.85+
- å‡å°‘æ¼æ£€å’Œè¯¯æ£€

---

### ä¼˜å…ˆçº§ 2ï¼šTable Transformer é›†æˆï¼ˆé¢„æœŸæå‡ 10-15%ï¼‰

**ä¸ºä»€ä¹ˆé‡è¦**ï¼š
- å½“å‰ pdfplumber å¯¹æ— è¾¹æ¡†è¡¨æ ¼æ”¯æŒå·®
- Table Transformer ä¸“é—¨ç”¨äºè¡¨æ ¼æ£€æµ‹å’Œç»“æ„è¯†åˆ«
- å¯¹å¤æ‚è¡¨æ ¼æ”¯æŒæ›´å¥½

**å®æ–½æ­¥éª¤**ï¼š

#### 1. å®‰è£…ä¾èµ–

```bash
# æ·»åŠ åˆ° requirements-extra.txt
pip install transformers torch torchvision
```

#### 2. åˆ›å»ºæ£€æµ‹å™¨ç±»

åˆ›å»ºæ–‡ä»¶ï¼š`src/figtabminer/detectors/table_transformer_detector.py`

```python
#!/usr/bin/env python3
"""
Table Transformer detector for table detection and structure recognition.
"""

import torch
from PIL import Image
from transformers import AutoImageProcessor, TableTransformerForObjectDetection
from typing import List, Dict
import numpy as np


class TableTransformerDetector:
    """Table Transformer detector wrapper"""
    
    def __init__(self):
        # Detection model
        self.detection_processor = AutoImageProcessor.from_pretrained(
            "microsoft/table-transformer-detection"
        )
        self.detection_model = TableTransformerForObjectDetection.from_pretrained(
            "microsoft/table-transformer-detection"
        )
        
        # Structure recognition model
        self.structure_processor = AutoImageProcessor.from_pretrained(
            "microsoft/table-transformer-structure-recognition"
        )
        self.structure_model = TableTransformerForObjectDetection.from_pretrained(
            "microsoft/table-transformer-structure-recognition"
        )
        
        # Move to GPU if available
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.detection_model.to(self.device)
        self.structure_model.to(self.device)
    
    def detect_tables(self, image_path: str, conf_threshold: float = 0.7) -> List[Dict]:
        """
        Detect tables in image.
        
        Returns:
            List of table detections with bbox and score
        """
        image = Image.open(image_path).convert("RGB")
        
        # Prepare inputs
        inputs = self.detection_processor(images=image, return_tensors="pt")
        inputs = {k: v.to(self.device) for k, v in inputs.items()}
        
        # Run detection
        with torch.no_grad():
            outputs = self.detection_model(**inputs)
        
        # Post-process
        target_sizes = torch.tensor([image.size[::-1]]).to(self.device)
        results = self.detection_processor.post_process_object_detection(
            outputs, 
            threshold=conf_threshold, 
            target_sizes=target_sizes
        )[0]
        
        tables = []
        for score, label, box in zip(results["scores"], results["labels"], results["boxes"]):
            if label == 0:  # Table class
                tables.append({
                    "bbox": box.cpu().numpy().tolist(),
                    "score": float(score.cpu().numpy()),
                    "label": "table"
                })
        
        return tables
    
    def recognize_structure(self, image_path: str, table_bbox: List[float]) -> Dict:
        """
        Recognize table structure (rows, columns, cells).
        
        Args:
            image_path: Path to image
            table_bbox: Table bounding box [x0, y0, x1, y1]
        
        Returns:
            Dict with rows, columns, cells
        """
        image = Image.open(image_path).convert("RGB")
        
        # Crop to table region
        table_crop = image.crop(table_bbox)
        
        # Prepare inputs
        inputs = self.structure_processor(images=table_crop, return_tensors="pt")
        inputs = {k: v.to(self.device) for k, v in inputs.items()}
        
        # Run structure recognition
        with torch.no_grad():
            outputs = self.structure_model(**inputs)
        
        # Post-process
        target_sizes = torch.tensor([table_crop.size[::-1]]).to(self.device)
        results = self.structure_processor.post_process_object_detection(
            outputs,
            threshold=0.6,
            target_sizes=target_sizes
        )[0]
        
        # Extract structure elements
        rows = []
        columns = []
        cells = []
        
        for score, label, box in zip(results["scores"], results["labels"], results["boxes"]):
            element = {
                "bbox": box.cpu().numpy().tolist(),
                "score": float(score.cpu().numpy())
            }
            
            label_id = int(label.cpu().numpy())
            if label_id == 0:  # Row
                rows.append(element)
            elif label_id == 1:  # Column
                columns.append(element)
            elif label_id == 2:  # Cell
                cells.append(element)
        
        return {
            "rows": rows,
            "columns": columns,
            "cells": cells
        }


def detect_tables_transformer(image_path: str, conf_threshold: float = 0.7) -> List[Dict]:
    """
    Convenience function for table detection.
    """
    detector = TableTransformerDetector()
    return detector.detect_tables(image_path, conf_threshold)
```

#### 3. é›†æˆåˆ°è¡¨æ ¼æå–

ä¿®æ”¹ `src/figtabminer/table_extract_v2.py`ï¼š

```python
# åœ¨æ–‡ä»¶å¼€å¤´æ·»åŠ 
try:
    from .detectors import table_transformer_detector
    TABLE_TRANSFORMER_AVAILABLE = True
except ImportError:
    TABLE_TRANSFORMER_AVAILABLE = False

# åœ¨ EnhancedTableExtractor ç±»ä¸­æ·»åŠ æ–¹æ³•
def _extract_with_table_transformer(self, pdf_path: str, ingest_data: dict) -> List[Dict]:
    """Extract tables using Table Transformer"""
    if not TABLE_TRANSFORMER_AVAILABLE:
        return []
    
    tables = []
    
    for page_idx, page_img_path in enumerate(ingest_data["page_images"]):
        try:
            # Detect tables
            detections = table_transformer_detector.detect_tables_transformer(
                page_img_path,
                conf_threshold=0.7
            )
            
            for det in detections:
                table_id = f"table_{len(tables):04d}"
                
                tables.append({
                    "item_id": table_id,
                    "type": "table",
                    "page_index": page_idx,
                    "bbox": det["bbox"],
                    "score": det["score"],
                    "method": "table_transformer"
                })
        
        except Exception as e:
            logger.warning(f"Table Transformer failed on page {page_idx}: {e}")
    
    return tables

# ä¿®æ”¹ extract() æ–¹æ³•ï¼Œæ·»åŠ  Table Transformer ç­–ç•¥
def extract(self, pdf_path: str, ingest_data: dict) -> List[Dict]:
    """Multi-strategy table extraction with Table Transformer"""
    all_tables = []
    
    # Strategy 1: Layout detection
    layout_tables = self._extract_from_layout(ingest_data)
    all_tables.extend(layout_tables)
    
    # Strategy 2: Table Transformer (NEW!)
    if TABLE_TRANSFORMER_AVAILABLE:
        tt_tables = self._extract_with_table_transformer(pdf_path, ingest_data)
        all_tables.extend(tt_tables)
        logger.info(f"Table Transformer found {len(tt_tables)} tables")
    
    # Strategy 3: pdfplumber (existing)
    pdfplumber_tables = self._extract_with_pdfplumber(pdf_path, ingest_data)
    all_tables.extend(pdfplumber_tables)
    
    # Deduplicate
    tables = self._deduplicate_tables(all_tables)
    
    return tables
```

#### 4. æµ‹è¯•

```bash
# æµ‹è¯• Table Transformer
python -c "
from src.figtabminer.detectors import table_transformer_detector
tables = table_transformer_detector.detect_tables_transformer('test_page.png')
print(f'Detected {len(tables)} tables')
"

# è¿è¡Œå®Œæ•´æµç¨‹
python scripts/run_pipeline.py --pdf data/samples/test.pdf
```

**é¢„æœŸæ•ˆæœ**ï¼š
- æ— è¾¹æ¡†è¡¨æ ¼è¯†åˆ«ï¼š40% â†’ 75%+
- å¤æ‚è¡¨æ ¼è¯†åˆ«ï¼š60% â†’ 85%+
- è¡¨æ ¼ç»“æ„è¯†åˆ«æ›´å‡†ç¡®

---

## ğŸ“Š é¢„æœŸæ€»ä½“æå‡

| æŒ‡æ ‡ | v1.3 | v1.4 (Caption) | v1.5 (+ YOLO) | v1.6 (+ Table) |
|------|------|----------------|---------------|----------------|
| Caption åŒ¹é… | 70% | **85%** âœ¨ | 85% | 85% |
| å›¾è¡¨æ£€æµ‹ F1 | 0.75 | 0.75 | **0.90** âœ¨ | 0.90 |
| è¡¨æ ¼æ£€æµ‹ F1 | 0.70 | 0.70 | 0.85 | **0.90** âœ¨ |
| æ— è¾¹æ¡†è¡¨æ ¼ | 40% | 40% | 40% | **75%** âœ¨ |

---

## ğŸ› ï¸ å®æ–½å»ºè®®

### æ–¹æ¡ˆ Aï¼šé€æ­¥å®æ–½ï¼ˆæ¨èï¼‰

1. **ç¬¬ 1 å¤©**ï¼šCaption ä¼˜åŒ–ï¼ˆå·²å®Œæˆ âœ…ï¼‰
2. **ç¬¬ 2-3 å¤©**ï¼šDocLayout-YOLO é›†æˆ
3. **ç¬¬ 4-5 å¤©**ï¼šTable Transformer é›†æˆ
4. **ç¬¬ 6 å¤©**ï¼šæµ‹è¯•å’Œè°ƒä¼˜

### æ–¹æ¡ˆ Bï¼šå¿«é€ŸéªŒè¯

1. **å…ˆæµ‹è¯• DocLayout-YOLO**ï¼ˆ2-3 å°æ—¶ï¼‰
   - å®‰è£…ä¾èµ–
   - åˆ›å»ºç®€å•çš„æ£€æµ‹è„šæœ¬
   - åœ¨å‡ ä¸ª PDF ä¸Šæµ‹è¯•æ•ˆæœ
   - å¦‚æœæ•ˆæœå¥½ï¼Œå†å®Œæ•´é›†æˆ

2. **å†æµ‹è¯• Table Transformer**ï¼ˆ2-3 å°æ—¶ï¼‰
   - åŒæ ·çš„æµç¨‹

---

## ğŸ’¡ æ³¨æ„äº‹é¡¹

### DocLayout-YOLO

**ä¼˜ç‚¹**ï¼š
- é€Ÿåº¦å¿«ï¼ˆYOLO æ¶æ„ï¼‰
- å‡†ç¡®ç‡é«˜
- ä¸“é—¨é’ˆå¯¹æ–‡æ¡£

**ç¼ºç‚¹**ï¼š
- æ¨¡å‹è¾ƒå¤§ï¼ˆ~200MBï¼‰
- é¦–æ¬¡ä¸‹è½½éœ€è¦æ—¶é—´
- éœ€è¦ GPU æ‰èƒ½å‘æŒ¥æœ€ä½³æ€§èƒ½

**é™çº§ç­–ç•¥**ï¼š
- å¦‚æœ GPU ä¸å¯ç”¨ï¼Œè‡ªåŠ¨é™çº§åˆ° CPU
- å¦‚æœæ¨¡å‹ä¸‹è½½å¤±è´¥ï¼Œé™çº§åˆ° PubLayNet
- å¦‚æœ PubLayNet å¤±è´¥ï¼Œé™çº§åˆ°åŸºç¡€æ–¹æ³•

### Table Transformer

**ä¼˜ç‚¹**ï¼š
- å¯¹æ— è¾¹æ¡†è¡¨æ ¼æ”¯æŒå¥½
- å¯ä»¥è¯†åˆ«è¡¨æ ¼ç»“æ„
- Microsoft å®˜æ–¹æ¨¡å‹

**ç¼ºç‚¹**ï¼š
- é€Ÿåº¦è¾ƒæ…¢ï¼ˆTransformer æ¶æ„ï¼‰
- æ¨¡å‹æ›´å¤§ï¼ˆ~300MBï¼‰
- å†…å­˜å ç”¨è¾ƒé«˜

**é™çº§ç­–ç•¥**ï¼š
- å¦‚æœå†…å­˜ä¸è¶³ï¼Œè·³è¿‡ Table Transformer
- å¦‚æœæ£€æµ‹å¤±è´¥ï¼Œä½¿ç”¨ pdfplumber
- ä¿ç•™å¤šç­–ç•¥èåˆæœºåˆ¶

---

## ğŸ¯ å¿«é€Ÿå¼€å§‹

### æµ‹è¯• Caption ä¼˜åŒ–ï¼ˆå·²å®Œæˆï¼‰

```bash
# è¿è¡Œæµ‹è¯•
python scripts/run_pipeline.py --pdf data/samples/test.pdf

# æ£€æŸ¥è¾“å‡º
cat data/outputs/*/manifest.json | grep -A 5 "caption"
```

### é›†æˆ DocLayout-YOLO

```bash
# 1. å®‰è£…
pip install doclayout-yolo

# 2. åˆ›å»ºæ£€æµ‹å™¨æ–‡ä»¶
mkdir -p src/figtabminer/detectors
# å¤åˆ¶ä¸Šé¢çš„ä»£ç åˆ° src/figtabminer/detectors/doclayout_detector.py

# 3. ä¿®æ”¹ layout_detect.py
# æ·»åŠ  DocLayout-YOLO æ”¯æŒ

# 4. æµ‹è¯•
python scripts/run_pipeline.py --pdf data/samples/test.pdf
```

### é›†æˆ Table Transformer

```bash
# 1. å®‰è£…
pip install transformers torch

# 2. åˆ›å»ºæ£€æµ‹å™¨æ–‡ä»¶
# å¤åˆ¶ä¸Šé¢çš„ä»£ç åˆ° src/figtabminer/detectors/table_transformer_detector.py

# 3. ä¿®æ”¹ table_extract_v2.py
# æ·»åŠ  Table Transformer æ”¯æŒ

# 4. æµ‹è¯•
python scripts/run_pipeline.py --pdf data/samples/test.pdf
```

---

## ğŸ“ˆ æ•ˆæœéªŒè¯

### å®šæ€§éªŒè¯

```bash
# è¿è¡Œå¯è§†åŒ–å·¥å…·
python tools/visualize_results.py

# åœ¨æµè§ˆå™¨ä¸­æŸ¥çœ‹
firefox extraction_report.html
```

æ£€æŸ¥ï¼š
- Caption æ˜¯å¦åŒ¹é…æ­£ç¡®ï¼Ÿ
- å›¾è¡¨æ£€æµ‹æ˜¯å¦æ›´å‡†ç¡®ï¼Ÿ
- è¡¨æ ¼è¯†åˆ«æ˜¯å¦æ›´å®Œæ•´ï¼Ÿ

### å®šé‡éªŒè¯ï¼ˆå¯é€‰ï¼‰

å¦‚æœæœ‰æ ‡æ³¨æ•°æ®ï¼š

```bash
python tools/evaluate_accuracy.py --save-report evaluation_v1.5.json
```

---

## ğŸ‰ æ€»ç»“

**v1.4 å·²å®Œæˆ**ï¼š
- âœ… Caption å…³è”ä¼˜åŒ–ï¼ˆç¼–å·åŒ¹é… + å­å›¾è¯†åˆ«ï¼‰

**v1.5 å¾…å®æ–½**ï¼š
- ğŸ“‹ DocLayout-YOLO é›†æˆï¼ˆé¢„æœŸ 2-3 å¤©ï¼‰
- ğŸ“‹ Table Transformer é›†æˆï¼ˆé¢„æœŸ 2-3 å¤©ï¼‰

**é¢„æœŸæ€»ä½“æå‡**ï¼š
- Caption åŒ¹é…ï¼š70% â†’ 85% âœ¨
- å›¾è¡¨æ£€æµ‹ï¼š0.75 â†’ 0.90 âœ¨
- è¡¨æ ¼æ£€æµ‹ï¼š0.70 â†’ 0.90 âœ¨

**å®æ–½å»ºè®®**ï¼š
1. å…ˆæµ‹è¯• DocLayout-YOLOï¼ˆæ•ˆæœæœ€æ˜æ˜¾ï¼‰
2. å†é›†æˆ Table Transformerï¼ˆå¦‚æœéœ€è¦ï¼‰
3. ä¿æŒé™çº§ç­–ç•¥ï¼ˆç¡®ä¿ç³»ç»Ÿç¨³å®šï¼‰

