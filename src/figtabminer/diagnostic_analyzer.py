#!/usr/bin/env python3
"""
Diagnostic Analyzer for FigTabMiner Critical Accuracy Fixes.

This module provides tools to analyze detection results and identify
common accuracy problems including:
- arXivç¼–å·è¢«è¯¯è¯†åˆ«ä¸ºfigure
- æ­£æ–‡è¢«è¯¯è¯†åˆ«ä¸ºtable
- ä¸‰çº¿è¡¨æ¼æ£€

Requirements: 1.1, 1.2, 1.3, 1.4, 1.5, 1.6
"""

import logging
from typing import List, Dict, Tuple, Optional, Any
from dataclasses import dataclass, field
import numpy as np
import cv2
from pathlib import Path

from .models import Detection
from . import bbox_utils
from . import utils

logger = utils.setup_logging(__name__)


@dataclass
class DiagnosticReport:
    """è¯Šæ–­æŠ¥å‘Šæ•°æ®æ¨¡å‹"""
    total_detections: int
    detections_by_type: Dict[str, int]
    arxiv_suspects: List[Tuple[Detection, Dict[str, Any]]]
    text_suspects: List[Tuple[Detection, Dict[str, Any]]]
    missed_tables: List[Dict[str, Any]]
    visualization_path: str
    summary: str
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'total_detections': self.total_detections,
            'detections_by_type': self.detections_by_type,
            'arxiv_suspects_count': len(self.arxiv_suspects),
            'text_suspects_count': len(self.text_suspects),
            'missed_tables_count': len(self.missed_tables),
            'visualization_path': self.visualization_path,
            'summary': self.summary
        }


def extract_detection_features(
    detection: Detection,
    image: np.ndarray
) -> Dict[str, Any]:
    """
    æå–æ£€æµ‹æ¡†çš„ç‰¹å¾
    
    Features:
        - position: (x_ratio, y_ratio) ç›¸å¯¹ä½ç½®
        - size: (width, height) ç»å¯¹å°ºå¯¸
        - area_ratio: å é¡µé¢é¢ç§¯æ¯”ä¾‹
        - aspect_ratio: å®½é«˜æ¯”
        - ink_density: å¢¨æ°´å¯†åº¦ï¼ˆé»‘è‰²åƒç´ æ¯”ä¾‹ï¼‰
        - edge_density: è¾¹ç¼˜å¯†åº¦
        - horizontal_lines: æ°´å¹³çº¿æ¡åƒç´ æ•°
        - vertical_lines: å‚ç›´çº¿æ¡åƒç´ æ•°
        - has_table_structure: æ˜¯å¦æœ‰è¡¨æ ¼ç»“æ„ç‰¹å¾
    
    Args:
        detection: Detectionå¯¹è±¡
        image: é¡µé¢å›¾åƒ
        
    Returns:
        ç‰¹å¾å­—å…¸
    """
    features = {}
    
    # è·å–å›¾åƒå°ºå¯¸
    h, w = image.shape[:2]
    page_area = h * w
    
    # è·å–bboxåæ ‡
    x0, y0, x1, y1 = [int(c) for c in detection.bbox]
    
    # Clampåˆ°å›¾åƒè¾¹ç•Œ
    x0, y0 = max(0, x0), max(0, y0)
    x1, y1 = min(w, x1), min(h, y1)
    
    # åŸºæœ¬å‡ ä½•ç‰¹å¾
    width = x1 - x0
    height = y1 - y0
    area = width * height
    
    features['position'] = (x0 / w, y0 / h)  # ç›¸å¯¹ä½ç½®
    features['center'] = ((x0 + x1) / 2 / w, (y0 + y1) / 2 / h)  # ä¸­å¿ƒç‚¹ç›¸å¯¹ä½ç½®
    features['size'] = (width, height)
    features['area'] = area
    features['area_ratio'] = area / page_area if page_area > 0 else 0
    features['aspect_ratio'] = width / height if height > 0 else float('inf')
    
    # æå–å›¾åƒåŒºåŸŸ
    if x1 > x0 and y1 > y0:
        crop = image[y0:y1, x0:x1]
        
        if crop.size > 0:
            # è½¬æ¢ä¸ºç°åº¦å›¾
            if len(crop.shape) == 3:
                gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)
            else:
                gray = crop
            
            # å¢¨æ°´å¯†åº¦ï¼ˆé»‘è‰²åƒç´ æ¯”ä¾‹ï¼‰
            _, binary = cv2.threshold(gray, 245, 255, cv2.THRESH_BINARY_INV)
            ink_pixels = np.count_nonzero(binary)
            features['ink_density'] = ink_pixels / binary.size if binary.size > 0 else 0
            
            # è¾¹ç¼˜å¯†åº¦
            edges = cv2.Canny(gray, 50, 150)
            edge_pixels = np.count_nonzero(edges)
            features['edge_density'] = edge_pixels / edges.size if edges.size > 0 else 0
            
            # æ£€æµ‹æ°´å¹³å’Œå‚ç›´çº¿æ¡
            h_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1))
            v_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 40))
            
            h_lines = cv2.morphologyEx(edges, cv2.MORPH_OPEN, h_kernel)
            v_lines = cv2.morphologyEx(edges, cv2.MORPH_OPEN, v_kernel)
            
            features['horizontal_lines'] = np.count_nonzero(h_lines)
            features['vertical_lines'] = np.count_nonzero(v_lines)
            
            # è¡¨æ ¼ç»“æ„ç‰¹å¾ï¼ˆæœ‰æ˜æ˜¾çš„æ°´å¹³å’Œå‚ç›´çº¿æ¡ï¼‰
            features['has_table_structure'] = (
                features['horizontal_lines'] > 100 and 
                features['vertical_lines'] > 100
            )
        else:
            # ç©ºåŒºåŸŸ
            features['ink_density'] = 0
            features['edge_density'] = 0
            features['horizontal_lines'] = 0
            features['vertical_lines'] = 0
            features['has_table_structure'] = False
    else:
        # æ— æ•ˆåŒºåŸŸ
        features['ink_density'] = 0
        features['edge_density'] = 0
        features['horizontal_lines'] = 0
        features['vertical_lines'] = 0
        features['has_table_structure'] = False
    
    return features


class DiagnosticAnalyzer:
    """
    è¯Šæ–­åˆ†æå™¨ï¼Œç”¨äºåˆ†ææ£€æµ‹ç»“æœå¹¶è¯†åˆ«é—®é¢˜æ¨¡å¼
    
    Requirements: 1.1, 1.2, 1.3, 1.4, 1.5, 1.6
    """
    
    def __init__(self):
        """åˆå§‹åŒ–è¯Šæ–­åˆ†æå™¨"""
        pass
    
    def analyze_detections(
        self,
        image_path: str,
        detections: List[Detection],
        ground_truth: Optional[List[Detection]] = None
    ) -> DiagnosticReport:
        """
        åˆ†ææ£€æµ‹ç»“æœ
        
        Args:
            image_path: å›¾åƒè·¯å¾„
            detections: æ£€æµ‹ç»“æœåˆ—è¡¨
            ground_truth: å¯é€‰çš„æ ‡æ³¨çœŸå€¼
            
        Returns:
            DiagnosticReport: åŒ…å«ç»Ÿè®¡ä¿¡æ¯ã€é—®é¢˜æ¨¡å¼å’Œå¯è§†åŒ–
        """
        logger.info(f"Analyzing detections for: {image_path}")
        
        # åŠ è½½å›¾åƒ
        image = cv2.imread(image_path)
        if image is None:
            logger.error(f"Failed to load image: {image_path}")
            return DiagnosticReport(
                total_detections=0,
                detections_by_type={},
                arxiv_suspects=[],
                text_suspects=[],
                missed_tables=[],
                visualization_path="",
                summary="Failed to load image"
            )
        
        image_shape = image.shape[:2]  # (height, width)
        
        # ç»Ÿè®¡æ£€æµ‹æ•°é‡
        total_detections = len(detections)
        detections_by_type = {}
        for det in detections:
            det_type = det.type
            detections_by_type[det_type] = detections_by_type.get(det_type, 0) + 1
        
        # è¯†åˆ«arXivè¯¯æŠ¥
        arxiv_suspects = self.identify_arxiv_false_positives(detections, image_shape)
        
        # è¯†åˆ«æ­£æ–‡è¯¯æŠ¥
        text_suspects = self.identify_text_false_positives(detections, image)
        
        # è¯†åˆ«æ¼æ£€çš„ä¸‰çº¿è¡¨
        missed_tables = self.identify_missed_three_line_tables(image, detections)
        
        # ç”Ÿæˆå¯è§†åŒ–
        problems = {
            'arxiv_suspects': [det for det, _ in arxiv_suspects],
            'text_suspects': [det for det, _ in text_suspects],
            'missed_tables': missed_tables
        }
        visualization_path = self.generate_visualization(image_path, detections, problems)
        
        # ç”ŸæˆæŠ¥å‘Š
        summary = self.generate_report(detections, problems)
        
        report = DiagnosticReport(
            total_detections=total_detections,
            detections_by_type=detections_by_type,
            arxiv_suspects=arxiv_suspects,
            text_suspects=text_suspects,
            missed_tables=missed_tables,
            visualization_path=visualization_path,
            summary=summary
        )
        
        logger.info(f"Diagnostic complete: {len(arxiv_suspects)} arXiv suspects, "
                   f"{len(text_suspects)} text suspects, {len(missed_tables)} missed tables")
        
        return report
    
    def identify_arxiv_false_positives(
        self,
        detections: List[Detection],
        image_shape: Tuple[int, int]
    ) -> List[Tuple[Detection, Dict[str, Any]]]:
        """
        è¯†åˆ«å¯èƒ½çš„arXivç¼–å·è¯¯æŠ¥
        
        arXivç¼–å·ç‰¹å¾ï¼š
        1. ä½ç½®ï¼šå·¦ä¸Šè§’ï¼ˆy < 10% page heightï¼‰
        2. å°ºå¯¸ï¼šå°æ¡†ï¼ˆarea < 5% page areaï¼‰
        3. å½¢çŠ¶ï¼šæ¨ªå‘çŸ©å½¢ï¼ˆ1.5 < aspect_ratio < 8.0ï¼‰
        
        Returns:
            List of (detection, features) tuples
        """
        suspects = []
        h, w = image_shape
        page_area = h * w
        
        for det in detections:
            # åªæ£€æŸ¥figureç±»å‹
            if det.type != 'figure':
                continue
            
            x0, y0, x1, y1 = det.bbox
            
            # è®¡ç®—ç‰¹å¾
            center_y = (y0 + y1) / 2
            width = x1 - x0
            height = y1 - y0
            area = width * height
            aspect_ratio = width / height if height > 0 else float('inf')
            
            # åˆ¤æ–­æ¡ä»¶
            is_top = center_y < h * 0.1  # ä¸Šæ–¹10%
            is_small = area < page_area * 0.05  # å°äº5%é¡µé¢é¢ç§¯
            is_horizontal = 1.5 < aspect_ratio < 8.0  # æ¨ªå‘çŸ©å½¢
            
            if is_top and is_small and is_horizontal:
                features = {
                    'center_y_ratio': center_y / h,
                    'area_ratio': area / page_area,
                    'aspect_ratio': aspect_ratio,
                    'reason': 'ä½ç½®ã€å°ºå¯¸ã€çºµæ¨ªæ¯”ç¬¦åˆarXivç‰¹å¾'
                }
                suspects.append((det, features))
                logger.debug(f"arXiv suspect: bbox={det.bbox}, features={features}")
        
        return suspects
    
    def identify_text_false_positives(
        self,
        detections: List[Detection],
        image: np.ndarray
    ) -> List[Tuple[Detection, Dict[str, Any]]]:
        """
        è¯†åˆ«å¯èƒ½çš„æ­£æ–‡è¯¯æŠ¥ä¸ºtable
        
        æ­£æ–‡è¯¯æŠ¥ç‰¹å¾ï¼š
        1. é«˜å¢¨æ°´å¯†åº¦ï¼ˆ> 80%ï¼‰
        2. æ— æ˜æ˜¾è¡¨æ ¼çº¿æ¡
        3. ä½è¡¨æ ¼ç»“æ„åˆ†æ•°
        4. ç½®ä¿¡åº¦ä¸é«˜ï¼ˆ0.5-0.7ä¹‹é—´ï¼‰
        
        Returns:
            List of (detection, features) tuples
        """
        suspects = []
        
        for det in detections:
            # åªæ£€æŸ¥tableç±»å‹
            if det.type != 'table':
                continue
            
            # æå–ç‰¹å¾
            features = extract_detection_features(det, image)
            
            # åˆ¤æ–­æ¡ä»¶
            high_text_density = features['ink_density'] > 0.8
            no_table_lines = (
                features['horizontal_lines'] < 100 and 
                features['vertical_lines'] < 100
            )
            low_structure_score = not features['has_table_structure']
            moderate_confidence = 0.5 <= det.score <= 0.7
            
            if high_text_density and no_table_lines and low_structure_score:
                features['reason'] = 'é«˜æ–‡å­—å¯†åº¦ä½†æ— è¡¨æ ¼ç»“æ„'
                suspects.append((det, features))
                logger.debug(f"Text FP suspect: bbox={det.bbox}, "
                           f"ink_density={features['ink_density']:.2f}, "
                           f"h_lines={features['horizontal_lines']}, "
                           f"v_lines={features['vertical_lines']}")
        
        return suspects
    
    def identify_missed_three_line_tables(
        self,
        image: np.ndarray,
        detections: List[Detection]
    ) -> List[Dict[str, Any]]:
        """
        è¯†åˆ«å¯èƒ½æ¼æ£€çš„ä¸‰çº¿è¡¨ï¼ˆåŒ…æ‹¬ä¸¤çº¿è¡¨ï¼‰
        
        ä½¿ç”¨img2tableåº“è¿›è¡Œè¡¨æ ¼æ£€æµ‹ï¼Œå°è¯•å¤šç§å‚æ•°ç»„åˆä»¥æ£€æµ‹ä¸åŒç±»å‹çš„è¡¨æ ¼
        
        Returns:
            List of candidate regions with features
        """
        candidates = []
        
        try:
            # å°è¯•ä½¿ç”¨img2tableåº“è¿›è¡Œè¡¨æ ¼æ£€æµ‹
            from img2table.document import Image as Img2TableImage
            
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ä¿å­˜å›¾åƒ
            import tempfile
            with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp:
                tmp_path = tmp.name
                cv2.imwrite(tmp_path, image)
            
            try:
                # ä½¿ç”¨img2tableæ£€æµ‹è¡¨æ ¼
                img_doc = Img2TableImage(src=tmp_path, detect_rotation=False)
                
                # å°è¯•å¤šç§å‚æ•°ç»„åˆä»¥æ£€æµ‹ä¸åŒç±»å‹çš„è¡¨æ ¼
                all_tables = []
                param_combinations = [
                    # ä¸‰çº¿è¡¨ï¼ˆæœ‰éšå¼è¡Œï¼‰
                    {"implicit_rows": True, "borderless_tables": False, "min_confidence": 20},
                    # ä¸¤çº¿è¡¨æˆ–æ— è¾¹æ¡†è¡¨æ ¼
                    {"implicit_rows": True, "borderless_tables": True, "min_confidence": 20},
                    # æ ‡å‡†è¡¨æ ¼
                    {"implicit_rows": False, "borderless_tables": False, "min_confidence": 20},
                    # æ›´ä½ç½®ä¿¡åº¦
                    {"implicit_rows": True, "borderless_tables": True, "min_confidence": 10},
                ]
                
                for params in param_combinations:
                    try:
                        tables = img_doc.extract_tables(**params)
                        logger.debug(f"img2table with params {params}: found {len(tables)} tables")
                        all_tables.extend(tables)
                    except Exception as e:
                        logger.debug(f"img2table failed with params {params}: {e}")
                        continue
                
                logger.info(f"img2table found {len(all_tables)} tables total (with duplicates)")
                
                # å»é‡ï¼šåˆå¹¶é‡å çš„è¡¨æ ¼
                unique_tables = []
                for table in all_tables:
                    table_bbox = table.bbox
                    x1, y1, x2, y2 = table_bbox.x1, table_bbox.y1, table_bbox.x2, table_bbox.y2
                    candidate_bbox = [float(x1), float(y1), float(x2), float(y2)]
                    
                    # æ£€æŸ¥æ˜¯å¦ä¸å·²æœ‰è¡¨æ ¼é‡å¤
                    is_duplicate = False
                    for existing_bbox in unique_tables:
                        iou = bbox_utils.bbox_iou(candidate_bbox, existing_bbox)
                        if iou > 0.7:  # é«˜åº¦é‡å è®¤ä¸ºæ˜¯é‡å¤
                            is_duplicate = True
                            break
                    
                    if not is_duplicate:
                        unique_tables.append(candidate_bbox)
                
                logger.info(f"After deduplication: {len(unique_tables)} unique tables")
                
                # æ£€æŸ¥æ¯ä¸ªæ£€æµ‹åˆ°çš„è¡¨æ ¼æ˜¯å¦å·²è¢«ç°æœ‰æ£€æµ‹è¦†ç›–
                for candidate_bbox in unique_tables:
                    is_covered = False
                    max_iou = 0.0
                    for det in detections:
                        if det.type == 'table':
                            iou = bbox_utils.bbox_iou(candidate_bbox, det.bbox)
                            max_iou = max(max_iou, iou)
                            if iou > 0.3:  # IoU > 0.3è®¤ä¸ºå·²è¦†ç›–
                                is_covered = True
                                break
                    
                    if not is_covered:
                        # è®¡ç®—è¡¨æ ¼ç‰¹å¾
                        x1, y1, x2, y2 = candidate_bbox
                        width = x2 - x1
                        height = y2 - y1
                        
                        candidate = {
                            'bbox': candidate_bbox,
                            'width': width,
                            'height': height,
                            'max_iou_with_existing': max_iou,
                            'reason': f'img2tableæ£€æµ‹åˆ°è¡¨æ ¼ä½†æœªè¢«ç°æœ‰æ£€æµ‹è¦†ç›– (size={width:.0f}x{height:.0f})'
                        }
                        candidates.append(candidate)
                        logger.info(f"Missed table candidate from img2table: bbox={candidate_bbox}")
                
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                import os
                try:
                    os.unlink(tmp_path)
                except:
                    pass
                    
        except ImportError:
            logger.warning("img2table library not available, falling back to OpenCV-based detection")
            # å¦‚æœimg2tableä¸å¯ç”¨ï¼Œä½¿ç”¨åŸæ¥çš„OpenCVæ–¹æ³•
            candidates = self._identify_missed_tables_opencv(image, detections)
        except Exception as e:
            logger.error(f"Error using img2table: {e}, falling back to OpenCV-based detection")
            candidates = self._identify_missed_tables_opencv(image, detections)
        
        logger.info(f"Found {len(candidates)} unique missed table candidates")
        return candidates
    
    def _identify_missed_tables_opencv(
        self,
        image: np.ndarray,
        detections: List[Detection]
    ) -> List[Dict[str, Any]]:
        """
        ä½¿ç”¨OpenCVæ–¹æ³•æ£€æµ‹æ¼æ£€çš„ä¸‰çº¿è¡¨ï¼ˆå¤‡ç”¨æ–¹æ³•ï¼‰
        
        Returns:
            List of candidate regions with features
        """
        candidates = []
        
        # è½¬æ¢ä¸ºç°åº¦å›¾
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # ä½¿ç”¨å¤šç§æ–¹æ³•æ£€æµ‹æ°´å¹³çº¿æ¡
        # æ–¹æ³•1: Cannyè¾¹ç¼˜æ£€æµ‹ + å½¢æ€å­¦æ“ä½œ
        edges = cv2.Canny(gray, 30, 100)
        
        # ä½¿ç”¨æ›´å°çš„kernelä»¥æ£€æµ‹æ›´ç»†çš„çº¿æ¡
        h_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (25, 1))
        h_lines_canny = cv2.morphologyEx(edges, cv2.MORPH_OPEN, h_kernel)
        
        # æ–¹æ³•2: ç›´æ¥åœ¨ç°åº¦å›¾ä¸Šæ£€æµ‹æš—çº¿
        _, binary = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)
        h_lines_thresh = cv2.morphologyEx(binary, cv2.MORPH_OPEN, h_kernel)
        
        # åˆå¹¶ä¸¤ç§æ–¹æ³•çš„ç»“æœ
        h_lines = cv2.bitwise_or(h_lines_canny, h_lines_thresh)
        
        # æŸ¥æ‰¾çº¿æ¡è½®å»“
        contours, _ = cv2.findContours(h_lines, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        # æå–çº¿æ¡ä¿¡æ¯
        min_line_length = image.shape[1] * 0.2
        lines = []
        for contour in contours:
            x, y, w, h = cv2.boundingRect(contour)
            if w >= min_line_length and h < 10:
                center_y = y + h // 2
                lines.append({
                    'x0': x,
                    'y': center_y,
                    'x1': x + w,
                    'width': w,
                    'bbox': (x, y, x + w, y + h)
                })
        
        # æŒ‰yåæ ‡æ’åº
        lines.sort(key=lambda line: line['y'])
        
        # åˆå¹¶ç›¸è¿‘çš„çº¿æ¡
        merged_lines = []
        if lines:
            current_line = lines[0]
            for next_line in lines[1:]:
                if abs(next_line['y'] - current_line['y']) < 5:
                    if next_line['width'] > current_line['width']:
                        current_line = next_line
                else:
                    merged_lines.append(current_line)
                    current_line = next_line
            merged_lines.append(current_line)
        
        logger.debug(f"OpenCV detected {len(merged_lines)} horizontal lines after merging")
        
        # æŸ¥æ‰¾3æ¡çº¿çš„ç»„åˆ
        if len(merged_lines) >= 3:
            for i in range(len(merged_lines) - 2):
                for j in range(i + 1, len(merged_lines) - 1):
                    for k in range(j + 1, len(merged_lines)):
                        line1 = merged_lines[i]
                        line2 = merged_lines[j]
                        line3 = merged_lines[k]
                        
                        gap1 = line2['y'] - line1['y']
                        gap2 = line3['y'] - line2['y']
                        total_height = line3['y'] - line1['y']
                        
                        if (gap1 >= 20 and gap2 >= 20 and 
                            50 <= total_height <= 500 and
                            min(gap1, gap2) / max(gap1, gap2) > 0.2):
                            
                            x_min = min(line1['x0'], line2['x0'], line3['x0'])
                            y_min = line1['y'] - 5
                            x_max = max(line1['x1'], line2['x1'], line3['x1'])
                            y_max = line3['y'] + 5
                            
                            if x_max > x_min and y_max > y_min:
                                candidate_bbox = [float(x_min), float(y_min), float(x_max), float(y_max)]
                                
                                # æ£€æŸ¥æ˜¯å¦å·²è¢«ç°æœ‰æ£€æµ‹è¦†ç›–
                                is_covered = False
                                max_iou = 0.0
                                for det in detections:
                                    if det.type == 'table':
                                        iou = bbox_utils.bbox_iou(candidate_bbox, det.bbox)
                                        max_iou = max(max_iou, iou)
                                        if iou > 0.3:
                                            is_covered = True
                                            break
                                
                                if not is_covered:
                                    y0, y1 = int(y_min), int(y_max)
                                    x0, x1 = int(x_min), int(x_max)
                                    
                                    y0 = max(0, y0)
                                    y1 = min(image.shape[0], y1)
                                    x0 = max(0, x0)
                                    x1 = min(image.shape[1], x1)
                                    
                                    if y1 > y0 and x1 > x0:
                                        region = gray[y0:y1, x0:x1]
                                        
                                        _, region_binary = cv2.threshold(region, 245, 255, cv2.THRESH_BINARY_INV)
                                        ink_density = np.count_nonzero(region_binary) / region_binary.size if region_binary.size > 0 else 0
                                        
                                        if ink_density > 0.05:
                                            candidate = {
                                                'bbox': candidate_bbox,
                                                'line_count': 3,
                                                'gap1': gap1,
                                                'gap2': gap2,
                                                'total_height': total_height,
                                                'ink_density': ink_density,
                                                'max_iou_with_existing': max_iou,
                                                'reason': f'OpenCVæ£€æµ‹åˆ°3æ¡æ°´å¹³çº¿ (gaps={gap1:.0f},{gap2:.0f}, ink={ink_density:.2%})'
                                            }
                                            candidates.append(candidate)
        
        # å»é‡
        unique_candidates = []
        for cand in candidates:
            is_duplicate = False
            for existing in unique_candidates:
                iou = bbox_utils.bbox_iou(cand['bbox'], existing['bbox'])
                if iou > 0.7:
                    is_duplicate = True
                    break
            if not is_duplicate:
                unique_candidates.append(cand)
        
        return unique_candidates
    
    def generate_visualization(
        self,
        image_path: str,
        detections: List[Detection],
        problems: Dict[str, List]
    ) -> str:
        """
        ç”Ÿæˆå¯è§†åŒ–å›¾åƒï¼Œæ ‡æ³¨æ£€æµ‹æ¡†å’Œé—®é¢˜åŒºåŸŸ
        
        Returns:
            Path to visualization image
        """
        # åŠ è½½å›¾åƒ
        image = cv2.imread(image_path)
        if image is None:
            logger.error(f"Failed to load image for visualization: {image_path}")
            return ""
        
        # ç»˜åˆ¶æ‰€æœ‰æ£€æµ‹æ¡†ï¼ˆç»¿è‰²ï¼‰
        for det in detections:
            x0, y0, x1, y1 = [int(c) for c in det.bbox]
            color = (0, 255, 0)  # ç»¿è‰²
            cv2.rectangle(image, (x0, y0), (x1, y1), color, 2)
            
            # æ·»åŠ æ ‡ç­¾
            label = f"{det.type} {det.score:.2f}"
            cv2.putText(image, label, (x0, y0 - 5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
        
        # ç»˜åˆ¶arXiv suspectsï¼ˆçº¢è‰²ï¼‰
        for det in problems.get('arxiv_suspects', []):
            x0, y0, x1, y1 = [int(c) for c in det.bbox]
            color = (0, 0, 255)  # çº¢è‰²
            cv2.rectangle(image, (x0, y0), (x1, y1), color, 3)
            cv2.putText(image, "arXiv?", (x0, y0 - 20), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
        
        # ç»˜åˆ¶text suspectsï¼ˆæ©™è‰²ï¼‰
        for det in problems.get('text_suspects', []):
            x0, y0, x1, y1 = [int(c) for c in det.bbox]
            color = (0, 165, 255)  # æ©™è‰²
            cv2.rectangle(image, (x0, y0), (x1, y1), color, 3)
            cv2.putText(image, "Text?", (x0, y0 - 20), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
        
        # ç»˜åˆ¶missed tablesï¼ˆè“è‰²è™šçº¿ï¼‰
        for candidate in problems.get('missed_tables', []):
            bbox = candidate['bbox']
            x0, y0, x1, y1 = [int(c) for c in bbox]
            color = (255, 0, 0)  # è“è‰²
            
            # ç»˜åˆ¶è™šçº¿çŸ©å½¢
            thickness = 2
            line_type = cv2.LINE_AA
            # é¡¶è¾¹
            cv2.line(image, (x0, y0), (x1, y0), color, thickness, line_type)
            # åº•è¾¹
            cv2.line(image, (x0, y1), (x1, y1), color, thickness, line_type)
            # å·¦è¾¹
            cv2.line(image, (x0, y0), (x0, y1), color, thickness, line_type)
            # å³è¾¹
            cv2.line(image, (x1, y0), (x1, y1), color, thickness, line_type)
            
            cv2.putText(image, "Missed?", (x0, y0 - 20), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
        
        # ä¿å­˜å¯è§†åŒ–å›¾åƒ
        output_path = image_path.replace('.png', '_diagnostic.png').replace('.jpg', '_diagnostic.jpg')
        cv2.imwrite(output_path, image)
        logger.info(f"Visualization saved to: {output_path}")
        
        return output_path
    
    def generate_report(
        self,
        detections: List[Detection],
        problems: Dict[str, List]
    ) -> str:
        """
        ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š
        
        Returns:
            Formatted report string
        """
        lines = []
        lines.append("=" * 60)
        lines.append("è¯Šæ–­æŠ¥å‘Š - FigTabMinerå‡†ç¡®åº¦åˆ†æ")
        lines.append("=" * 60)
        lines.append("")
        
        # æ€»ä½“ç»Ÿè®¡
        lines.append(f"æ€»æ£€æµ‹æ•°: {len(detections)}")
        
        # æŒ‰ç±»å‹ç»Ÿè®¡
        by_type = {}
        for det in detections:
            by_type[det.type] = by_type.get(det.type, 0) + 1
        
        for det_type, count in by_type.items():
            lines.append(f"  - {det_type}: {count}")
        lines.append("")
        
        # arXivè¯¯æŠ¥
        arxiv_suspects = problems.get('arxiv_suspects', [])
        lines.append(f"ğŸš¨ arXivç¼–å·è¯¯æŠ¥å«Œç–‘: {len(arxiv_suspects)}")
        if arxiv_suspects:
            lines.append("  ç‰¹å¾: å·¦ä¸Šè§’å°æ¡†ï¼Œæ¨ªå‘çŸ©å½¢")
            for i, det in enumerate(arxiv_suspects[:5], 1):  # åªæ˜¾ç¤ºå‰5ä¸ª
                lines.append(f"  {i}. bbox={[f'{c:.1f}' for c in det.bbox]}, "
                           f"score={det.score:.3f}, detector={det.detector}")
        lines.append("")
        
        # æ­£æ–‡è¯¯æŠ¥
        text_suspects = problems.get('text_suspects', [])
        lines.append(f"ğŸš¨ æ­£æ–‡è¯¯æŠ¥ä¸ºtableå«Œç–‘: {len(text_suspects)}")
        if text_suspects:
            lines.append("  ç‰¹å¾: é«˜æ–‡å­—å¯†åº¦ï¼Œæ— è¡¨æ ¼çº¿æ¡")
            for i, det in enumerate(text_suspects[:5], 1):
                lines.append(f"  {i}. bbox={[f'{c:.1f}' for c in det.bbox]}, "
                           f"score={det.score:.3f}, detector={det.detector}")
        lines.append("")
        
        # æ¼æ£€çš„ä¸‰çº¿è¡¨
        missed_tables = problems.get('missed_tables', [])
        lines.append(f"ğŸš¨ å¯èƒ½æ¼æ£€çš„è¡¨æ ¼: {len(missed_tables)}")
        if missed_tables:
            lines.append("  ç‰¹å¾: æœªè¢«ç°æœ‰æ£€æµ‹è¦†ç›–çš„è¡¨æ ¼åŒºåŸŸ")
            for i, candidate in enumerate(missed_tables[:5], 1):
                bbox = candidate['bbox']
                reason = candidate.get('reason', 'æœªçŸ¥åŸå› ')
                
                # æ ¹æ®å€™é€‰æ¥æºæ˜¾ç¤ºä¸åŒçš„ä¿¡æ¯
                if 'gap1' in candidate and 'gap2' in candidate:
                    # OpenCVæ£€æµ‹çš„ä¸‰çº¿è¡¨
                    lines.append(f"  {i}. bbox={[f'{c:.1f}' for c in bbox]}, "
                               f"gaps=({candidate['gap1']:.1f}, {candidate['gap2']:.1f})")
                else:
                    # img2tableæ£€æµ‹çš„è¡¨æ ¼
                    lines.append(f"  {i}. bbox={[f'{c:.1f}' for c in bbox]}")
                
                lines.append(f"      åŸå› : {reason}")
        lines.append("")
        
        # å»ºè®®
        lines.append("ğŸ’¡ ä¿®å¤å»ºè®®:")
        if arxiv_suspects:
            lines.append("  1. å®æ–½arXivè¿‡æ»¤å™¨ï¼ˆåŸºäºä½ç½®+å°ºå¯¸+OCRéªŒè¯ï¼‰")
        if text_suspects:
            lines.append("  2. æé«˜tableæ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼åˆ°0.6")
            lines.append("  3. æ·»åŠ æ–‡å­—å¯†åº¦æ£€æµ‹è¿‡æ»¤å™¨")
        if missed_tables:
            lines.append("  4. ä½¿ç”¨img2tableæˆ–é™ä½æ£€æµ‹å™¨ç½®ä¿¡åº¦é˜ˆå€¼ä»¥æ£€æµ‹æ›´å¤šè¡¨æ ¼")
            lines.append("  5. è€ƒè™‘ä½¿ç”¨Table Transformerè¿›è¡ŒäºŒæ¬¡éªŒè¯")
        
        lines.append("")
        lines.append("=" * 60)
        
        report = "\n".join(lines)
        return report
